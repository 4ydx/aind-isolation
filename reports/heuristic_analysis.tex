\documentclass[10pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{listings}

\title{Heuristic Analysis}
\author{Nathan Findley}
\date{March 2017}

\begin{document}

\maketitle
\tableofcontents

\begin{abstract}

Minimax alpha-beta pruning with iterative deepening uses a heuristic in
order to determine which branches should be kept and which should be pruned.
four different strategies are explored with the hope that a heuristic that outperforms
the ID Improved default heuristic can be found.

\end{abstract}

\section{Primarily Follow The Opponent}

Favor moves where the player encroaches on the opponents final move. Otherwise,
follow the opponent around the board.

\begin{lstlisting}[language=Python]
    playerMoves = game.get_legal_moves(player)
    opponentMoves = game.get_legal_moves(game.get_opponent(player))
    if len(opponentMoves) == 1:
        for o in opponentMoves:
            for p in playerMoves:
                if o == p:
                    return float("+inf")

    playerAt = game.get_player_location(player)
    opponentAt = game.get_player_location(game.get_opponent(player))

    xDiff = playerAt[0] - opponentAt[0]
    yDiff = playerAt[1] - opponentAt[1]
    denom = float(xDiff*xDiff + yDiff*yDiff)
    if denom == 0:
        return float("+inf")
    return float(1.0/denom)
\end{lstlisting}

\begin{verbatim}
*************************
 Evaluating: ID_Improved 
*************************

Playing Matches:
----------
  Match 1: ID_Improved vs   Random    	Result: 186 to 14
  Match 2: ID_Improved vs   MM_Null   	Result: 172 to 28
  Match 3: ID_Improved vs   MM_Open   	Result: 148 to 52
  Match 4: ID_Improved vs MM_Improved 	Result: 156 to 44
  Match 5: ID_Improved vs   AB_Null   	Result: 156 to 44
  Match 6: ID_Improved vs   AB_Open   	Result: 131 to 69
  Match 7: ID_Improved vs AB_Improved 	Result: 137 to 63


Results:
----------
ID_Improved         77.57%

*************************
   Evaluating: Student   
*************************

Playing Matches:
----------
  Match 1:   Student   vs   Random    	Result: 191 to 9
  Match 2:   Student   vs   MM_Null   	Result: 172 to 28
  Match 3:   Student   vs   MM_Open   	Result: 149 to 51
  Match 4:   Student   vs MM_Improved 	Result: 133 to 67
  Match 5:   Student   vs   AB_Null   	Result: 160 to 40
  Match 6:   Student   vs   AB_Open   	Result: 129 to 71
  Match 7:   Student   vs AB_Improved 	Result: 119 to 81


Results:
----------
Student             75.21%
\end{verbatim}

This strategy appears to be roughly equivalent to the default ID Improved heuristic.

\section{Consume The Opponent's Movement Space}

Favor moves where the player encroaches on the opponent's moves or follow them around
the board. Also uses the idea of trying to stop an opponent that suddenly has limited movement.

\begin{lstlisting}[language=Python]
    playerMoves = game.get_legal_moves(player)
    opponentMoves = game.get_legal_moves(game.get_opponent(player))
    if len(opponentMoves) == 1:
        for o in opponentMoves:
            for p in playerMoves:
                if o == p:
                    return float("+inf")

    matchedMoves = 0
    centerAt = board_center(game)
    for o in opponentMoves:
        for p in playerMoves:
            if o == p:
                matchedMoves += 10
    if matchedMoves > 0:
        return float(matchedMoves)

    playerAt = game.get_player_location(player)
    opponentAt = game.get_player_location(game.get_opponent(player))

    xDiff = playerAt[0] - opponentAt[0]
    yDiff = playerAt[1] - opponentAt[1]
    denom = float(xDiff*xDiff + yDiff*yDiff)
    if denom == 0:
        return float("+inf")
    return float(1.0/denom)
\end{lstlisting}

\begin{verbatim}
*************************
 Evaluating: ID_Improved 
*************************

Playing Matches:
----------
  Match 1: ID_Improved vs   Random    	Result: 184 to 16
  Match 2: ID_Improved vs   MM_Null   	Result: 174 to 26
  Match 3: ID_Improved vs   MM_Open   	Result: 157 to 43
  Match 4: ID_Improved vs MM_Improved 	Result: 141 to 59
  Match 5: ID_Improved vs   AB_Null   	Result: 161 to 39
  Match 6: ID_Improved vs   AB_Open   	Result: 136 to 64
  Match 7: ID_Improved vs AB_Improved 	Result: 123 to 77


Results:
----------
ID_Improved         76.86%

*************************
   Evaluating: Student   
*************************

Playing Matches:
----------
  Match 1:   Student   vs   Random    	Result: 181 to 19
  Match 2:   Student   vs   MM_Null   	Result: 168 to 32
  Match 3:   Student   vs   MM_Open   	Result: 146 to 54
  Match 4:   Student   vs MM_Improved 	Result: 138 to 62
  Match 5:   Student   vs   AB_Null   	Result: 156 to 44
  Match 6:   Student   vs   AB_Open   	Result: 127 to 73
  Match 7:   Student   vs AB_Improved 	Result: 121 to 79


Results:
----------
Student             74.07%
\end{verbatim}

Seeing that the value drops below 75\% is not encouraging.

\section{Remain Near The Center}

Favor moves that position the player closer to the center of the board.

\begin{lstlisting}[language=Python]
    centerAt = board_center(game)
    playerAt = game.get_player_location(player)

    xDiff = playerAt[0] - centerAt[0]
    yDiff = playerAt[1] - centerAt[1]
    denom = float(xDiff*xDiff + yDiff*yDiff)
    if denom == 0:
        return float("+inf")
    return float(1.0/denom)
\end{lstlisting}

\begin{verbatim}
*************************
 Evaluating: ID_Improved 
*************************

Playing Matches:
----------
  Match 1: ID_Improved vs   Random    	Result: 179 to 21
  Match 2: ID_Improved vs   MM_Null   	Result: 176 to 24
  Match 3: ID_Improved vs   MM_Open   	Result: 148 to 52
  Match 4: ID_Improved vs MM_Improved 	Result: 146 to 54
  Match 5: ID_Improved vs   AB_Null   	Result: 154 to 46
  Match 6: ID_Improved vs   AB_Open   	Result: 127 to 73
  Match 7: ID_Improved vs AB_Improved 	Result: 126 to 74


Results:
----------
ID_Improved         75.43%

*************************
   Evaluating: Student   
*************************

Playing Matches:
----------
  Match 1:   Student   vs   Random    	Result: 180 to 20
  Match 2:   Student   vs   MM_Null   	Result: 162 to 38
  Match 3:   Student   vs   MM_Open   	Result: 138 to 62
  Match 4:   Student   vs MM_Improved 	Result: 131 to 69
  Match 5:   Student   vs   AB_Null   	Result: 142 to 58
  Match 6:   Student   vs   AB_Open   	Result: 138 to 62
  Match 7:   Student   vs AB_Improved 	Result: 127 to 73


Results:
----------
Student             72.71%
\end{verbatim}

This ends up being the most disappointing set of results.  This is clearly not
a winning strategy.

\section{}

\begin{lstlisting}[language=Python]
\end{lstlisting}

\begin{verbatim}
\end{verbatim}

\section{Results}

The ID Improved heuristic consistently achieves scores from 75-78\% based on testing.
The four heuristics presented are not nearly good enough to overcome this range unfortunately.
It has been made crystal clear to me that I am not approaching this problem from the proper
perspective.  All of my attempts are, possibly, too simplistic in their approach due to not
taking enough time to think about patterns that might present themselves when dealing with
this particular version of isolation.

Among all four contenders, "Primarily Follow The Opponent" is the best option.  The primary
reason is that it appears to be the highest scoring heuristic.  I like the idea of coming up
with strategies that highly favor being able to see "horizon" results before they happen, unfortunately
I am not sure how to do that in an isolation scenario with chess-like knight movement.  As such
highly favoring a single move that includes the possibility of taking the opponents final move
is where my strategy stopped.  Following the opponent is an attempt at making this more likely
though I have to admit that I am simply working off of a gut feeling rather than any real reason
to believe that being close to the opponent will actually create such an opportunity.

\section{Beyond Project Scope - Breaking Changes}

The following results were obtained by changing the way that the iterative deepening
evaluates layers above depth == 1.  If one makes the changes below so that greater than and
less than comparisions become strictly greater or strictly less than, the search space is
expanded but the win percentages increase.  Doing this will result in the agent test.py
failing so I have not included it in my final result, but this was an interesting accidental
discovery.  This version seems far superior.  Both agents ran with the default ID Improved heuristic.

\begin{lstlisting}[language=Python]
# evaluate all branches and return the highest/lowest scoring tuple
for m in legal_moves:
	if current_move == (-1, -1):
		current_move = m

	if maximizing_player:
		...
		# CHANGED if score >= beta:
		if score > beta:
		...
	else:	
		...
		# CHANGED if score <= alpha:
		if score < alpha:
		...
\end{lstlisting}

\begin{verbatim}
*************************
 Evaluating: ID_Improved 
*************************

Playing Matches:
----------
  Match 1: ID_Improved vs   Random    	Result: 184 to 16
  Match 2: ID_Improved vs   MM_Null   	Result: 174 to 26
  Match 3: ID_Improved vs   MM_Open   	Result: 158 to 42
  Match 4: ID_Improved vs MM_Improved 	Result: 142 to 58
  Match 5: ID_Improved vs   AB_Null   	Result: 162 to 38
  Match 6: ID_Improved vs   AB_Open   	Result: 146 to 54
  Match 7: ID_Improved vs AB_Improved 	Result: 140 to 60


Results:
----------
ID_Improved         79.00%

*************************
   Evaluating: Student   
*************************

Playing Matches:
----------
  Match 1:   Student   vs   Random    	Result: 185 to 15
  Match 2:   Student   vs   MM_Null   	Result: 178 to 22
  Match 3:   Student   vs   MM_Open   	Result: 159 to 41
  Match 4:   Student   vs MM_Improved 	Result: 139 to 61
  Match 5:   Student   vs   AB_Null   	Result: 157 to 43
  Match 6:   Student   vs   AB_Open   	Result: 138 to 62
  Match 7:   Student   vs AB_Improved 	Result: 128 to 72


Results:
----------
Student             77.43%
\end{verbatim}

\end{document}
